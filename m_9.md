# M9: Robustness & Cross-Validation (Momentum)

## Purpose
Stress‑test the momentum strategy and validate its stability out‑of‑sample via parameter sweeps, rolling walk‑forward cross‑validation, cost sensitivity, and subperiod analyses, in line with momentum_TRD.md.

## Objectives
- Run grid search over formation/holding parameters: J ∈ {3,6,9,12}, K ∈ {1,3,6,12}.
- Perform rolling walk‑forward CV: 36‑month train, 12‑month validate, no look‑ahead.
- Evaluate cost sensitivity across realistic frictions (e.g., 0/10/25/50 bps per side).
- Produce subperiod/regime diagnostics (pre‑COVID, crash, recovery, recent years; optional bull/bear regimes by VN‑Index).
- Report stability: selection frequency of (J,K), dispersion of OOS metrics, and degradation vs IS.

## Scope
- In‑scope: parameter grid definition, rolling splits, evaluation plumbing via existing backtester/metrics, cost sweeps, subperiod slicing, CSV/fig outputs, config + validation, tests, docs, optional CLI.
- Out‑of‑scope: advanced model selection (Bayesian optimization), ML factor discovery, intraday execution simulation, alternative asset classes.

---

## Inputs and Outputs

### Inputs
- `data/clean/momentum.parquet` (from M4): monthly signals with at least [`month_end`,`ticker`,`momentum`,`valid`,`decile`,`pct_rank`].
- `data/clean/portfolio_holdings.parquet` (optional, from M5) if reusing precomputed holdings; otherwise, rebuild internally for each (J,K).
- Daily/monthly returns utilities and calendars (M3), backtest engine (M7), metrics/stats (M8).
- `config/data.yml` additions under `cv` and `robustness` (validated via Pydantic):
  - `cv.train_months` (int, default `36`, `>=12`).
  - `cv.valid_months` (int, default `12`, `>=1`).
  - `cv.j_grid` (list[int], default `[3,6,9,12]`, each `>=1`).
  - `cv.k_grid` (list[int], default `[1,3,6,12]`, each `>=1`).
  - `cv.skip_days` (int, default `5`, `>=0`).
  - `cv.metric` (str enum, default `sharpe`, options: `sharpe|alpha_nw|ir_vs_benchmark|sortino`).
  - `cv.tie_breaker` (str enum, default `lower_turnover`, options: `lower_turnover|higher_return|lower_k`).
  - `robustness.cost_bps_grid` (list[float], default `[0,10,25,50]`, each `>=0`).
  - `robustness.subperiods` (list[dict], optional; each with `name,start,end`).
  - `robustness.regimes` (optional; rule to define bull/bear by VN‑Index, e.g., `sma_window`, `drawdown_threshold`).

Notes
- If separate `strategy.yml`/`backtest.yml` are introduced later, mirror fields there; for now, keep under `config/data.yml` for simplicity and tests.

### Outputs
- CSV: `data/clean/cv_results.csv` — per fold and parameter combo:
  - `fold_id`, `train_start`, `train_end`, `valid_start`, `valid_end`, `J`, `K`, `skip_days`, `metric`, `value`, `turnover`, `cost_bps`, plus selected key metrics (e.g., `sharpe`, `alpha_nw`, `ret_ann`, `vol_ann`).
- CSV: `data/clean/cv_selection.csv` — best (J,K) per fold with tie‑break info and selection frequency.
- CSV: `data/clean/cv_oos_summary.csv` — aggregated OOS metrics across folds for the selected policy and for each fixed (J,K).
- CSV: `data/clean/robustness_costs.csv` — performance vs cost assumptions for chosen (J,K) and optionally all combos.
- CSV: `data/clean/robustness_subperiods.csv` — metrics by named subperiods and/or regimes.
- (Optional) Figures under `data/clean/figs/`: heatmaps of metrics over (J,K), selection frequency bar chart, cost sensitivity curves.

---

## Algorithm Details
1. Parameter Grid
   - Construct Cartesian product `G = {(J,K) | J ∈ j_grid, K ∈ k_grid}` with `skip_days` fixed (default 5) unless overridden.
2. Rolling Splits (Walk‑Forward)
   - Define monthly folds: for fold anchor month `t`, training window `[t-36, t-1]`, validation window `[t, t+11]` aligned to month‑ends.
   - Move anchor by `valid_months` (12) each iteration; stop when validation end exceeds data end.
   - No look‑ahead: only use information ≤ train end for parameter selection; validate strictly OOS.
3. Within‑Fold Evaluation
   - For each `(J,K) ∈ G`:
     - Build signals/holdings using M4/M5 logic with `J` and `K` and the configured `skip_days` and selection policy; ensure formation uses only data up to each formation month.
     - Backtest on the validation window via M7, applying configured trading frictions; compute metrics via M8 (Sharpe, alpha with Newey‑West SE, IR vs VN‑Index, turnover, drawdown, etc.).
   - Select best `(J,K)` by `cv.metric` on validation; tie‑break using `cv.tie_breaker` (e.g., prefer lower turnover, then lower K, then higher return).
4. Across‑Fold Aggregation
   - Report per‑fold choices and OOS performance; compute selection frequency of `(J,K)` and dispersion of OOS metric (mean, std, 5/95p).
   - Also report OOS metrics for each fixed `(J,K)` across all folds (to assess stability vs dynamic selection).
5. Cost Sensitivity
   - For the overall best `(J,K)` (by average OOS metric) — and optionally for all `(J,K)` — re‑evaluate on the full sample using cost grid `robustness.cost_bps_grid` and emit performance vs cost.
6. Subperiod/Regime Robustness
   - Define named subperiods (default from momentum_TRD.md: pre‑COVID, COVID crash, recovery, recent) and compute metrics for the chosen `(J,K)`; optional regime split by VN‑Index trend/drawdown rules.
7. Determinism & Seeds
   - Use `src/utils.py` (`set_seed`, `fixed_seed`) for any stochastic steps (e.g., bootstrap CIs in M8) to ensure reproducibility.

---

## API (Public)
- Module: `src/cv.py`
  - `rolling_splits(month_ends: pd.DatetimeIndex, train_months: int, valid_months: int) -> list[tuple[pd.Timestamp,pd.Timestamp,pd.Timestamp,pd.Timestamp]]`
    - Returns list of `(train_start, train_end, valid_start, valid_end)` windows.
  - `param_grid(j_grid: list[int], k_grid: list[int]) -> list[tuple[int,int]]`
  - `evaluate_combo(j: int, k: int, windows: tuple, config: dict) -> dict`
    - Builds holdings/backtests on validation window only, returns metrics dict with required keys.
  - `select_best(results: list[dict], metric: str, tie_breaker: str) -> dict`
  - `cross_validate(config: dict) -> tuple[pd.DataFrame,pd.DataFrame,pd.DataFrame]`
    - Returns `(cv_results, cv_selection, cv_oos_summary)`.
- Module: `src/robustness.py`
  - `cost_sensitivity(best_params: dict, costs_bps: list[float], config: dict) -> pd.DataFrame`
  - `subperiod_metrics(best_params: dict, subperiods: list[dict], config: dict) -> pd.DataFrame`

APIs reuse M4/M5 (signals/portfolio), M7 (backtest), and M8 (metrics).

---

## Data Model
- `cv_results.csv`
  - Columns: `fold_id,int`, `train_start,ts`, `train_end,ts`, `valid_start,ts`, `valid_end,ts`, `J,int`, `K,int`, `skip_days,int`, `metric,str`, `value,float`, `sharpe,float`, `alpha_nw,float`, `alpha_nw_t,float`, `ret_ann,float`, `vol_ann,float`, `max_dd,float`, `turnover,float`, `cost_bps,float`.
- `cv_selection.csv`
  - Columns: `fold_id,int`, `J,int`, `K,int`, `metric,str`, `value,float`, `tie_breaker,str`, `note,str`.
- `cv_oos_summary.csv`
  - Columns: `policy,str` in {`selected_per_fold`,`fixed_(J,K)`}, `J,int|NaN`, `K,int|NaN`, `n_folds,int`, `metric,str`, `value_mean,float`, `value_std,float`, `ret_ann,float`, `vol_ann,float`, `alpha_nw,float`, `alpha_nw_t,float`.
- `robustness_costs.csv`
  - Columns: `J,int`, `K,int`, `cost_bps,float`, `sharpe,float`, `ret_ann,float`, `alpha_nw,float`, `turnover,float`.
- `robustness_subperiods.csv`
  - Columns: `name,str`, `start,ts`, `end,ts`, `J,int`, `K,int`, `sharpe,float`, `ret_ann,float`, `alpha_nw,float`, `max_dd,float`, `turnover,float`.

---

## Config Additions
Example `config/data.yml` extensions:

```yaml
cv:
  train_months: 36
  valid_months: 12
  j_grid: [3, 6, 9, 12]
  k_grid: [1, 3, 6, 12]
  skip_days: 5
  metric: sharpe            # sharpe | alpha_nw | ir_vs_benchmark | sortino
  tie_breaker: lower_turnover

robustness:
  cost_bps_grid: [0, 10, 25, 50]
  subperiods:
    - {name: pre_covid,   start: '2015-01-31', end: '2019-12-31'}
    - {name: covid_crash, start: '2020-02-29', end: '2020-04-30'}
    - {name: recovery,    start: '2020-05-31', end: '2022-12-31'}
    - {name: recent,      start: '2023-01-31', end: '2025-12-31'}
  regimes:
    sma_window: 200       # optional; define bull/bear by price vs SMA
    drawdown_threshold: 0.2
```

Validation
- `train_months >= 12`, `valid_months >= 1`.
- `j_grid` and `k_grid` non‑empty; all entries `>= 1`.
- `metric` in allowed set; `tie_breaker` in allowed set.
- `cost_bps_grid` entries `>= 0`.
- Subperiods have `start <= end` and overlap the data.

Backward compatibility: If `cv`/`robustness` omitted, skip CV/robustness features.

---

## CLI (Optional)
Add:
- `scripts/compute_cv.py`
  - Args: `-c/--config` (default `config/data.yml`), `--dry-run`.
  - Behavior: runs cross‑validation; writes `cv_results.csv`, `cv_selection.csv`, `cv_oos_summary.csv`; prints selection frequency and OOS summary.
- `scripts/compute_robustness.py`
  - Args: `-c/--config` (default `config/data.yml`), `--params J K`, `--all-combos`.
  - Behavior: runs cost sensitivity and subperiod metrics for chosen or all `(J,K)`; writes robustness CSVs and optional figures.

Usage examples
- `poetry run python scripts/compute_cv.py -c config/data.yml`
- `poetry run python scripts/compute_robustness.py -c config/data.yml --params 12 6`

---

## Tests
Create `tests/test_cv.py` and `tests/test_robustness.py`.

- Unit: rolling splits
  - 36/12 windows advance by 12 months; last fold truncated gracefully; no overlap errors; boundaries align to month‑ends.
- Unit: grid generation and selection
  - `param_grid([3,6],[1,3])` yields four combos; selection honors metric and tie‑breaker; deterministic with fixed results.
- Unit: no look‑ahead
  - Synthetic series where a parameter only excels after a change point: ensure selection uses only training info; OOS metric reflects expected degradation/improvement.
- Unit: cost sensitivity monotonicity
  - On a toy backtest with fixed turnover, increasing cost bps reduces net return and Sharpe.
- Integration: end‑to‑end CV
  - Small synthetic data (e.g., 72 months) with known best `(J,K)` OOS; confirm `cv_selection` picks it in ≥80% of folds and `cv_oos_summary` aggregates correctly.
- Integration: subperiod metrics
  - Named slices yield correct counts and date containment; metrics match recomputed references.

Testing helpers
- Absolute imports from `src`; use `tmp_path` for I/O; seed via `set_seed`/`fixed_seed`.

---

## Acceptance Criteria
- Config schema accepts/validates `cv.*` and `robustness.*` with defaults and constraints.
- `cv_results.csv`, `cv_selection.csv`, and `cv_oos_summary.csv` written with the specified schemas.
- Selection frequency and OOS summaries indicate stable performance; (J,K) choice consistent across folds or degradation quantified.
- Cost sensitivity and subperiod CSVs emitted; figures optional.
- Deterministic: repeated runs with identical inputs/config produce identical outputs.
- Quality: `poetry run pytest -k "cv or robustness" -q` passes; new functions have docstrings and type hints; no changes to unrelated modules/tests.

---

## Integration with Previous Milestones
- M4: Uses momentum signals and deciles; re‑computes as needed for varying J.
- M5: Builds portfolios with K‑month overlap; reused internally per combo.
- M6: Applies trading frictions consistently during validation and robustness sweeps.
- M7: Relies on backtest engine for monthly rebalancing and PnL; no leakage.
- M8: Uses metrics/stats (Sharpe, IR, alpha with Newey‑West) for evaluation; optional bootstrap CIs.

---

## Non‑Functional Requirements
- Performance: vectorized pandas; CV over 4×4 grid with ~5 folds should complete in minutes on a laptop.
- Determinism: seed all stochastic components; sorted joins; stable ranking methods.
- Auditability: persist config snapshot/hash with outputs; log selections and metrics.

---

## Implementation Notes
- Cache intermediate holdings/returns per `(J,K)` to avoid recomputation across folds when valid windows overlap.
- Ensure calendar alignment; use the same month‑end grid as signals and backtester.
- For tie‑breakers, prefer lower turnover to reduce cost sensitivity; fall back to lower K, then higher return.
- Subperiods should clip to available data and warn on empty ranges.
- Consider parallelizing across `(J,K)` with care for determinism (fix seed and avoid shared mutable state).

---

## Deliverables
- Code: `src/cv.py`, `src/robustness.py` with APIs above; minimal additions to config model.
- CLI: `scripts/compute_cv.py`, `scripts/compute_robustness.py` (optional).
- Tests: `tests/test_cv.py`, `tests/test_robustness.py` with unit and e2e coverage.
- Data: `data/clean/cv_results.csv`, `data/clean/cv_selection.csv`, `data/clean/cv_oos_summary.csv`, `data/clean/robustness_costs.csv`, `data/clean/robustness_subperiods.csv` produced by tests/CLI.
- Docs: This `m_8.md` and function docstrings.

---
