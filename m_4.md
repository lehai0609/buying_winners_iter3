# M4: Momentum Signal Computation (J‑month, Deciles)

## Purpose
Deliver a reliable cross‑sectional momentum signal computed from historical OHLCV, using a J‑month lookback with an optional formation gap, and assigning deciles each month. The output enables downstream portfolio construction/evaluation in later milestones.

## Objectives
- Compute monthly momentum signal for each ticker from clean OHLCV.
- Support J‑month lookback and G‑month formation gap (default 12‑1 style: `J=12`, `G=1`).
- Assign cross‑sectional deciles (1–10) per formation month, with ties and sparse months handled deterministically.
- Persist results to configured outputs and expose a simple API and optional CLI.
- Integrate with prior milestones’ data cleaning, anomaly/hard‑error handling, and configuration schema.

## Scope
- In‑scope: signal computation, decile assignment, I/O, config + validation, tests, documentation, CLI wrapper.
- Out‑of‑scope: portfolio weighting/turnover, transaction costs, backtest PnL (future milestones).

---

## Inputs and Outputs

### Inputs
- `config/data.yml` (validated by Pydantic):
  - `data_dir`: root data directory.
  - `ohlcv_glob`: default `*.parquet` (used upstream).
  - `min_volume`: non‑negative volume filter used upstream; can be applied as an additional guard.
  - Proposed new section (nested):
    - `signals.momentum.lookback_months` (int, default `12`, `>=1`).
    - `signals.momentum.gap_months` (int, default `1`, `>=0`).
    - `signals.momentum.n_deciles` (int, default `10`, `>=2`).
    - `signals.momentum.min_months_history` (int, default `J + G`, `>= J + G`).
    - `signals.momentum.min_names_per_month` (int, default `50`).
    - `signals.momentum.exclude_hard_errors` (bool, default `true`).
- Clean OHLCV parquet from M1 (keeps flagged rows): `data/clean/ohlcv.parquet`.
- Optional filters:
  - `data/clean/hard_errors.csv` (M2): rows to exclude if `exclude_hard_errors=true`.

### Outputs
- Parquet: `data/clean/momentum.parquet` with monthly rows per ticker:
  - `ticker` (str)
  - `month` (month‑end date, `datetime64[ns]`)
  - `momentum` (float, cumulative return over window, net of gap)
  - `decile` (int 1–10)
  - `pct_rank` (float in [0,1])
  - `n_months_used` (int)
  - `valid` (bool; has sufficient history and finite signal)
  - `window_start` / `window_end` (optional audit fields; inclusive/exclusive)
- Optional CSV summary: `data/clean/momentum_summary.csv` per `month`:
  - `month`, `n_names`, `n_valid`, `n_deciles_used`, `min_signal`, `max_signal`.

---

## Algorithm Details
1. Monthly aggregation
   - Resample daily OHLCV to month‑end by taking the last trading day’s `close` and optional `volume`.
   - Require at least one trading day per month; months with no trades are absent.
2. Monthly returns
   - For each `ticker`, compute `r_t = P_t / P_{t-1} − 1` from month‑end closes.
3. Lookback window (J, G)
   - For formation month `t`, the momentum window is `[t − G − J, t − G)` on a monthly grid.
   - Compute cumulative return: `momentum_t = prod_{m in window}(1 + r_m) − 1`.
   - Mark `valid=false` if fewer than `J` returns available within window, or any non‑finite values.
   - Set `n_months_used` to actual count contributing to the product.
4. Cross‑sectional ranking/deciles
   - Per formation month, filter `valid` rows.
   - Require at least `min_names_per_month` to assign deciles; otherwise set `decile`/`pct_rank = NaN` but keep rows.
   - Use deterministic ranks: `pct_rank = rank(method="average") / (n_valid − 1)` when `n_valid > 1`, else `NaN`.
   - Bin by quantiles with `n_deciles` via `qcut(duplicates="drop")`. If unique values < bins, reduce effective bins and record `n_deciles_used` in summary.
5. Exclusions
   - If `exclude_hard_errors`, drop rows that join to `hard_errors.csv` (on `ticker` and `date`/`month` if available). Otherwise rely on `valid` filter only.

---

## Module and API Design
Add a new module: `src/momentum.py`.

- `compute_monthly_prices(df: pd.DataFrame, close_col: str = "close") -> pd.DataFrame`
  - Input schema: `['ticker','date','close',('volume', optional)]` daily rows.
  - Output schema: `['ticker','month','close']` month‑end close per ticker.

- `compute_monthly_returns(monthly_px: pd.DataFrame) -> pd.DataFrame`
  - Input: `['ticker','month','close']`. Output adds `ret`.

- `compute_momentum(returns: pd.DataFrame, lookback: int, gap: int, min_months_history: int | None = None) -> pd.DataFrame`
  - Returns DataFrame with `['ticker','month','momentum','n_months_used','valid']`.

- `assign_deciles(signal_df: pd.DataFrame, n_deciles: int, min_names_per_month: int) -> pd.DataFrame`
  - Adds `decile` and `pct_rank` per `month` group; preserves unassigned rows with NaN.

- `compute_momentum_signals(cfg: DataConfig | dict) -> pd.DataFrame`
  - Orchestrates: load clean OHLCV (and `hard_errors` if configured), aggregate to monthly, compute returns, compute momentum, assign deciles, write outputs. Returns the final DataFrame.

Notes
- Use absolute imports (`from src.momentum import compute_momentum_signals`).
- Keep functions pure where possible; centralize I/O in the orchestrator.
- Avoid ad‑hoc randomness; no seeding required.

---

## Configuration (Pydantic)
Extend existing config model with `signals.momentum` fields listed above. Validate:
- `lookback_months >= 1`, `gap_months >= 0`, `n_deciles >= 2`.
- `min_months_history >= lookback_months + gap_months`.
- `min_names_per_month >= 1`.

Backward compatibility: If `signals.momentum` is omitted, use safe defaults.

---

## CLI (Optional)
Add a simple script `scripts/compute_momentum.py`:
- Arguments: `-c/--config path` (default `config/data.yml`), `--dry-run`.
- Behavior: loads config, calls `compute_momentum_signals`, writes outputs, prints a brief summary (months processed, coverage, path to outputs).
- Usage:
  - `poetry run python scripts/compute_momentum.py -c config/data.yml`

Later, this can be replaced by a package entrypoint if desired.

---

## Tests
Create `tests/test_momentum.py` covering unit + integration. Keep deterministic and fast.

- Unit: monthly aggregation
  - Synthetic daily series for one ticker across 3 months with known month‑ends. Assert last‑day close is used.
- Unit: monthly returns
  - Verify `ret` equals `P_t/P_{t-1} − 1` and is `NaN` on first available month.
- Unit: momentum windowing
  - Given a 15‑month return series, `J=12`, `G=1`, check that the window excludes the most recent month and includes exactly 12 prior months. Assert product matches manual calculation and `n_months_used == 12`.
- Unit: insufficient history
  - With `J=6`, `G=1`, provide only 5 months; expect `valid=false`, `momentum=NaN`.
- Unit: decile assignment
  - Construct a formation month with 10 unique signals; expect deciles 1..10 one each. With duplicates, ensure bins remain deterministic and counts logical.
- Unit: sparse cross‑section
  - With `n_valid < min_names_per_month`, deciles/pct_rank remain `NaN` but rows are kept.
- Integration: exclude hard errors
  - Small dataset where a month is present in `hard_errors.csv`; when `exclude_hard_errors=true`, ensure that row is dropped before signal computation.
- Integration: end‑to‑end
  - Build a tiny OHLCV fixture (2 tickers, 18 months), run `compute_momentum_signals` and assert file creation, schema, and a few spot‑values.

Testing helpers
- Use absolute imports from `src`.
- Avoid network/filesystem outside the workspace; write temporary files under `tmp_path` when needed.

---

## Acceptance Criteria
- Config schema accepts/validates `signals.momentum.*` with defaults and constraints.
- Functionality:
  - `compute_momentum_signals` returns a DataFrame with expected columns and no duplicate `(ticker, month)`.
  - For the canonical `12‑1` setup, toy series produce matching manual results.
  - Deciles assigned for months with `>= min_names_per_month` valid names; unassigned otherwise.
  - Outputs written to `data/clean/momentum.parquet` and optional summary CSV.
- Quality:
  - `poetry run pytest -k momentum -q` passes on all new tests.
  - Docstrings and type hints present in new functions.
  - No changes to unrelated modules/tests.

---

## Integration with Previous Milestones
- M0: Setup — no changes required; respect project layout and Poetry config.
- M1: Ingest/Clean — consume `data/clean/ohlcv.parquet`. If ROC/adjusted fields exist, default to `close` unless config specifies otherwise.
- M2: Coverage/Anomalies — if `exclude_hard_errors=true`, join and exclude offending `(ticker,date/month)` before aggregation. Anomalies are kept but may be filtered upstream if configured.
- M3: Any utilities/config — extend Pydantic config in place; reuse existing logging and file I/O helpers if available (e.g., `src/data_io.py`).

---

## Non‑Functional Requirements
- Performance: vectorized pandas; able to process thousands of tickers × 20 years under a few seconds/minutes on a laptop.
- Determinism: no randomness; same inputs/config yield identical outputs.
- Robustness: clear `valid` flags; NaNs handled; no silent drops of data outside configured rules.

---

## Implementation Notes
- Ensure month keys are normalized to the exchange’s last trading day end‑of‑month; if calendar utilities exist upstream, reuse them.
- Use stable sorts/ranks to keep assignments deterministic.
- Record `window_start`/`window_end` for auditability if helpful in debugging.
- Keep the new module self‑contained and small; orchestrator does I/O, pure functions do math.

---

## Deliverables
- Code: `src/momentum.py` with APIs above, plus any minimal glue in config models.
- CLI: `scripts/compute_momentum.py` (optional but recommended).
- Tests: `tests/test_momentum.py` with unit and e2e tests as specified.
- Data: `data/clean/momentum.parquet` and (optional) `data/clean/momentum_summary.csv` produced by tests/CLI.
- Docs: This `m_4.md` and function docstrings.

---


